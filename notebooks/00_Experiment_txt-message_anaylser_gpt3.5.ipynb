{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completion.use_jedi = False\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from ki_gegen_rechts import llm_chains\n",
    "from ki_gegen_rechts.analyser import parallel_text_analyser_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "# Table of Content\n",
    "\n",
    "- [1. General Information](#cap1)\n",
    "- [2. Hatespeech Analyser Full Chain](#cap2)\n",
    "  - [2.1 Define example messages](#cap3) \n",
    "  - [2.2 Define LLM settings](#cap4)\n",
    "  - [2.3 Example: Analyse single message](#cap5)\n",
    "  - [2.4 View result of example message](#cap6)\n",
    "  - [2.5 Example: Analyse batch of messages](#cap7)    \n",
    "- [3. Deconstruct full analyser chain into components](#cap8)\n",
    "  - [3.1 Hatespeech Detector Chain](#cap9)\n",
    "  - [3.2 Hatespeech Validator Chain](#cap10)\n",
    "  - [3.3 Hatespeech Classifier Chain](#cap11)\n",
    "  - [3.4 Right-wing Rater Chain](#cap12)\n",
    "  - [3.5 OpenAI Moderator](#cap13)\n",
    "- [4. Conclusion and next steps](#last) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General Information <a id=\"cap1\"></a>\n",
    "\n",
    "This project explores OpenAI's GPT-3.5 turbo and moderation layer to identify hate speech within text messages. It's crucial to understand that hate speech is a sensitive topic and always requires human oversight. One of the main goals is to create a more granular dataset to better address hate speech and right-wing extremism, which will be valuable for fine tuning future models.\n",
    "\n",
    ">  Caution: This notebook contains examples of hate speech, including antisemitism, sexism and other forms of hate speech. These examples, whether they are created for this project or collected from external sources, are strictly for educational and research purposes. They do not reflect my personal views.\n",
    "\n",
    "For further reading, consider checking out OpenAI's blog post on using [GPT-4 for content moderation](https://openai.com/blog/using-gpt-4-for-content-moderation), which might offer additional insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hatespeech Analyser Full Chain <a id=\"cap2\"></a>\n",
    "\n",
    "For the Hatespeech Analyser I am using mainly Langchain to build my LLM chains. Each chain consists of a custom prompt, a LLM (OpenAI gpt3.5-turbo) and JSON Parser with custom format instructions. The input of the chains is a single message.\n",
    "\n",
    "The full chain combines 4 LLM Chains and one moderator chain (More details in the scripts and in [Section 3](#cap8)):\n",
    "\n",
    "\n",
    "| Chain                  | Description                                                                                                                                                                              |\n",
    "|-----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Hatespeech Detector   | Analyzes messages to determine the presence of hatespeech, categorizing responses as \"Direct Hatespeech\", \"No Hatespeech\", etc., and provides an explanation for its classification.    |\n",
    "| Hatespeech Validator  | Similar to the Detector, it evaluates messages for hatespeech using a different prompt, incorporating the Detector's output in its analysis to validate the presence of hatespeech.       |\n",
    "| Hatespeech Classifier | Identifies the specific type of hatespeech present in a message (e.g., \"racism\", \"sexism\") and further categorizes the message as \"Offensive Insult\", \"Personal Experience\", or \"Historical Reference\". |\n",
    "| Right-wing Rater      | Examines messages for signs of right-wing ideologies, assigning a severity rating on a scale from 0 to 3, where 0 indicates no right-wing content and 3 signals a clear indication of right-wing ideology that warrants reporting. |\n",
    "| Moderator Chain       | Uses OpenAI's moderation model to check the content of the message                                        |\n",
    "\n",
    "In this iteration I'm running the most chains in parallel which aren't dependent or connected. Only the Hatespeech Validator needs the classification output of the Hatespeech Detector.\n",
    "\n",
    "See the concept draw below to understand how the chains are connected.\n",
    "\n",
    "#### Concept Draw of the full analyzer chain:\n",
    "\n",
    "<img src=\"../visuals/concept_llm_chains.svg\">\n",
    "\n",
    "To better understand the full chain I've added an example message with the outputs to the concept.\n",
    "\n",
    "#### Example output of the full analyzer chain:\n",
    "\n",
    "<img src=\"../visuals/concept_llm_with_example_output.svg\">\n",
    "\n",
    "I will first use the full analyzer chain and show you the results. Afterwards in section 3 I will deconstruct each chain into the components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define example messages  <a id=\"cap3\"></a>\n",
    "\n",
    "- These message are from the web or constructed and DO NOT replicate my opinion!\n",
    "- The messages are in german, please use a translator to understand the content.\n",
    "- The messages contain antisemitism, racism, sexism and other hatespeech forms.\n",
    "- \"Ich mag Bananen\" = \"I like Bananas\" is meant to be a neutral check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"message\": \"Diese gierigen Juden gehören vergast - leider hat Hilter seine Arbeit damals nicht beendet.\"},\n",
    "    {\"message\": \"Als Kind wurde ich immer als Neger beschimpft\"},\n",
    "    {\"message\": \"Adolf Hitler war ein deutscher Politiker. Mit seiner Schrift Mein Kampf (1925/26) prägte er die antisemitische und rassistische, auf Eroberung von Lebensraum ausgerichtete Ideologie des Nationalsozialismus.\"},\n",
    "    {\"message\": \"Ich mag Bananen\"},\n",
    "    {\"message\": \"Du dumme Fotze, ich ficke dein Leben\"},\n",
    "    {\"message\": \"Du Schwuchtel!\"},\n",
    "    {\"message\": \"Scheiß Neger, die erlauben sich wie immer alles - sollen mal wieder zurück in den Dschungel\"},\n",
    "    {\"message\": \"Diese scheiß Grünen, die uns nur alles verbieten und wegnehmen. 88 - der einzig wahre Führer, der die deutschen Bedürfnisse verstanden hat.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define LLM Settings <a id=\"cap4\"></a>\n",
    "- I am using OpenAI gpt3.5 turbo 1106 (Why not gpt4? tbh to save some money)\n",
    "- setting temperature to 0.0 and a seed to try to get deterministic results (is the seed implemented in Langchain?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.0, model_kwargs={\"seed\": 0}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Example: Analyse single message <a id=\"cap5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Diese gierigen Juden gehören vergast - leider hat Hilter seine Arbeit damals nicht beendet.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = examples[0] # using the first message\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser_full_chain = parallel_text_analyser_chains(llm)\n",
    "result = analyser_full_chain.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"detection\": {\n",
      "        \"detector\": {\n",
      "            \"classification\": \"Direct hate speech\",\n",
      "            \"explanation\": \"The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is to disparage and promote hatred towards this group.\"\n",
      "        },\n",
      "        \"validator\": {\n",
      "            \"classification\": \"Direct hate speech\",\n",
      "            \"explanation\": \"I agree with the previous expert's classification. The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is clearly to disparage and promote hatred towards this group.\"\n",
      "        }\n",
      "    },\n",
      "    \"classifier\": {\n",
      "        \"classification\": \"Offensive insult\",\n",
      "        \"racism\": true,\n",
      "        \"anitsemitism\": true,\n",
      "        \"homophobia\": false,\n",
      "        \"ableism\": false,\n",
      "        \"violence\": true,\n",
      "        \"sexism\": false,\n",
      "        \"other_hate_speech\": false,\n",
      "        \"explanation\": \"The message contains offensive and hateful language directed at Jewish people, promoting violence and expressing antisemitic sentiments.\"\n",
      "    },\n",
      "    \"right_wing_rater\": {\n",
      "        \"right_wing_indicator\": true,\n",
      "        \"rating\": \"Category 3\",\n",
      "        \"explanation\": \"The message contains explicit and extreme right-wing rhetoric, advocating for the genocide of Jewish people. It openly promotes violence and hatred based on racial supremacy, which is a severe violation of German law. Immediate action is required to report the content and notify law enforcement.\"\n",
      "    },\n",
      "    \"moderator\": {\n",
      "        \"message\": \"Diese gierigen Juden geh\\u00f6ren vergast - leider hat Hilter seine Arbeit damals nicht beendet.\",\n",
      "        \"mod_results\": {\n",
      "            \"categories\": {\n",
      "                \"harassment\": true,\n",
      "                \"harassment_threatening\": true,\n",
      "                \"hate\": true,\n",
      "                \"hate_threatening\": true,\n",
      "                \"self_harm\": false,\n",
      "                \"self_harm_instructions\": false,\n",
      "                \"self_harm_intent\": false,\n",
      "                \"sexual\": false,\n",
      "                \"sexual_minors\": false,\n",
      "                \"violence\": true,\n",
      "                \"violence_graphic\": false,\n",
      "                \"self-harm\": false,\n",
      "                \"sexual/minors\": false,\n",
      "                \"hate/threatening\": true,\n",
      "                \"violence/graphic\": false,\n",
      "                \"self-harm/intent\": false,\n",
      "                \"self-harm/instructions\": false,\n",
      "                \"harassment/threatening\": true\n",
      "            },\n",
      "            \"category_scores\": {\n",
      "                \"harassment\": 0.9950785636901855,\n",
      "                \"harassment_threatening\": 0.9740835428237915,\n",
      "                \"hate\": 0.9758500456809998,\n",
      "                \"hate_threatening\": 0.7414653301239014,\n",
      "                \"self_harm\": 8.119581252685748e-06,\n",
      "                \"self_harm_instructions\": 7.503008987441717e-07,\n",
      "                \"self_harm_intent\": 4.811929102288559e-06,\n",
      "                \"sexual\": 5.383280586102046e-05,\n",
      "                \"sexual_minors\": 6.507869443339587e-07,\n",
      "                \"violence\": 0.9802851676940918,\n",
      "                \"violence_graphic\": 0.00483097555115819,\n",
      "                \"self-harm\": 8.119581252685748e-06,\n",
      "                \"sexual/minors\": 6.507869443339587e-07,\n",
      "                \"hate/threatening\": 0.7414653301239014,\n",
      "                \"violence/graphic\": 0.00483097555115819,\n",
      "                \"self-harm/intent\": 4.811929102288559e-06,\n",
      "                \"self-harm/instructions\": 7.503008987441717e-07,\n",
      "                \"harassment/threatening\": 0.9740835428237915\n",
      "            },\n",
      "            \"flagged\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 View results <a id=\"cap6\"></a>\n",
    "\n",
    "Let's format the results to get a better overview.\n",
    "- The first table show the string classification of each chain and the \"expert's\" explanation.\n",
    "- The red dots in the second table indicates that the category applies (True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ki_gegen_rechts.utils import pretty_tables_single_result\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "df_evaluation, df_explanations = pretty_tables_single_result(result)\n",
    "txt = message[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message: Diese gierigen Juden gehören vergast - leider hat Hilter seine Arbeit damals nicht beendet.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>detector</th>\n",
       "      <td>Direct hate speech</td>\n",
       "      <td>The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is to disparage and promote hatred towards this group.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validator</th>\n",
       "      <td>Direct hate speech</td>\n",
       "      <td>I agree with the previous expert's classification. The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is clearly to disparage and promote hatred towards this group.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <td>Offensive insult</td>\n",
       "      <td>The message contains offensive and hateful language directed at Jewish people, promoting violence and expressing antisemitic sentiments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_wing_rater</th>\n",
       "      <td>Category 3</td>\n",
       "      <td>The message contains explicit and extreme right-wing rhetoric, advocating for the genocide of Jewish people. It openly promotes violence and hatred based on racial supremacy, which is a severe violation of German law. Immediate action is required to report the content and notify law enforcement.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classification  \\\n",
       "detector          Direct hate speech   \n",
       "validator         Direct hate speech   \n",
       "classifier          Offensive insult   \n",
       "right_wing_rater          Category 3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                               Explanation  \n",
       "detector                                                                                                The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is to disparage and promote hatred towards this group.  \n",
       "validator                                    I agree with the previous expert's classification. The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is clearly to disparage and promote hatred towards this group.  \n",
       "classifier                                                                                                                                                                        The message contains offensive and hateful language directed at Jewish people, promoting violence and expressing antisemitic sentiments.  \n",
       "right_wing_rater  The message contains explicit and extreme right-wing rhetoric, advocating for the genocide of Jewish people. It openly promotes violence and hatred based on racial supremacy, which is a severe violation of German law. Immediate action is required to report the content and notify law enforcement.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Original message: {txt}\")\n",
    "df_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8df08 th {\n",
       "  width: 5px;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8df08 td.row_heading.level0 {\n",
       "  font-size: 10pt;\n",
       "}\n",
       "#T_8df08 th.col_heading.level1 {\n",
       "  writing-mode: vertical-rl;\n",
       "  transform: rotateZ(180deg);\n",
       "  height: 150px;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_8df08_row0_col0, #T_8df08_row0_col1, #T_8df08_row0_col2, #T_8df08_row0_col6, #T_8df08_row0_col12, #T_8df08_row0_col13, #T_8df08_row0_col14, #T_8df08_row0_col15, #T_8df08_row0_col16, #T_8df08_row0_col18, #T_8df08_row0_col19, #T_8df08_row0_col20, #T_8df08_row0_col22, #T_8df08_row0_col23, #T_8df08_row0_col24 {\n",
       "  color: grey;\n",
       "}\n",
       "#T_8df08_row0_col3, #T_8df08_row0_col4, #T_8df08_row0_col5, #T_8df08_row0_col7, #T_8df08_row0_col8, #T_8df08_row0_col9, #T_8df08_row0_col10, #T_8df08_row0_col11, #T_8df08_row0_col17, #T_8df08_row0_col21, #T_8df08_row0_col25 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8df08\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_8df08_level0_col0\" class=\"col_heading level0 col0\" colspan=\"7\">Hate Speech Classifier</th>\n",
       "      <th id=\"T_8df08_level0_col7\" class=\"col_heading level0 col7\" >Right Wing Rater</th>\n",
       "      <th id=\"T_8df08_level0_col8\" class=\"col_heading level0 col8\" colspan=\"18\">Moderator Results</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8df08_level1_col0\" class=\"col_heading level1 col0\" >other_hate_speech</th>\n",
       "      <th id=\"T_8df08_level1_col1\" class=\"col_heading level1 col1\" >sexism</th>\n",
       "      <th id=\"T_8df08_level1_col2\" class=\"col_heading level1 col2\" >ableism</th>\n",
       "      <th id=\"T_8df08_level1_col3\" class=\"col_heading level1 col3\" >racism</th>\n",
       "      <th id=\"T_8df08_level1_col4\" class=\"col_heading level1 col4\" >anitsemitism</th>\n",
       "      <th id=\"T_8df08_level1_col5\" class=\"col_heading level1 col5\" >violence</th>\n",
       "      <th id=\"T_8df08_level1_col6\" class=\"col_heading level1 col6\" >homophobia</th>\n",
       "      <th id=\"T_8df08_level1_col7\" class=\"col_heading level1 col7\" >right_wing_indicator</th>\n",
       "      <th id=\"T_8df08_level1_col8\" class=\"col_heading level1 col8\" >harassment</th>\n",
       "      <th id=\"T_8df08_level1_col9\" class=\"col_heading level1 col9\" >harassment_threatening</th>\n",
       "      <th id=\"T_8df08_level1_col10\" class=\"col_heading level1 col10\" >hate</th>\n",
       "      <th id=\"T_8df08_level1_col11\" class=\"col_heading level1 col11\" >hate_threatening</th>\n",
       "      <th id=\"T_8df08_level1_col12\" class=\"col_heading level1 col12\" >self_harm</th>\n",
       "      <th id=\"T_8df08_level1_col13\" class=\"col_heading level1 col13\" >self_harm_instructions</th>\n",
       "      <th id=\"T_8df08_level1_col14\" class=\"col_heading level1 col14\" >self_harm_intent</th>\n",
       "      <th id=\"T_8df08_level1_col15\" class=\"col_heading level1 col15\" >sexual</th>\n",
       "      <th id=\"T_8df08_level1_col16\" class=\"col_heading level1 col16\" >sexual_minors</th>\n",
       "      <th id=\"T_8df08_level1_col17\" class=\"col_heading level1 col17\" >violence</th>\n",
       "      <th id=\"T_8df08_level1_col18\" class=\"col_heading level1 col18\" >violence_graphic</th>\n",
       "      <th id=\"T_8df08_level1_col19\" class=\"col_heading level1 col19\" >self-harm</th>\n",
       "      <th id=\"T_8df08_level1_col20\" class=\"col_heading level1 col20\" >sexual/minors</th>\n",
       "      <th id=\"T_8df08_level1_col21\" class=\"col_heading level1 col21\" >hate/threatening</th>\n",
       "      <th id=\"T_8df08_level1_col22\" class=\"col_heading level1 col22\" >violence/graphic</th>\n",
       "      <th id=\"T_8df08_level1_col23\" class=\"col_heading level1 col23\" >self-harm/intent</th>\n",
       "      <th id=\"T_8df08_level1_col24\" class=\"col_heading level1 col24\" >self-harm/instructions</th>\n",
       "      <th id=\"T_8df08_level1_col25\" class=\"col_heading level1 col25\" >harassment/threatening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8df08_row0_col0\" class=\"data row0 col0\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col1\" class=\"data row0 col1\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col2\" class=\"data row0 col2\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col3\" class=\"data row0 col3\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col4\" class=\"data row0 col4\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col5\" class=\"data row0 col5\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col6\" class=\"data row0 col6\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col7\" class=\"data row0 col7\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col8\" class=\"data row0 col8\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col9\" class=\"data row0 col9\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col10\" class=\"data row0 col10\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col11\" class=\"data row0 col11\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col12\" class=\"data row0 col12\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col13\" class=\"data row0 col13\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col14\" class=\"data row0 col14\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col15\" class=\"data row0 col15\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col16\" class=\"data row0 col16\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col17\" class=\"data row0 col17\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col18\" class=\"data row0 col18\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col19\" class=\"data row0 col19\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col20\" class=\"data row0 col20\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col21\" class=\"data row0 col21\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col22\" class=\"data row0 col22\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col23\" class=\"data row0 col23\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col24\" class=\"data row0 col24\" >●</td>\n",
       "      <td id=\"T_8df08_row0_col25\" class=\"data row0 col25\" >●</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x117d61dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation # I worked the whole time in vscode, the formatting is a bit different -> need to add borders\n",
    "# unfortunately the red dots will not be displayed if I upload the notebook, so I will add the results as images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Content](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Example: Analyse batch of messages <a id=\"cap7\"></a>\n",
    "\n",
    "Because the analyser is based on Langchain's parallel chain you can use all corresponding methods like .batch or the asynchronous functions (not tested yet). I'm working on a visualisation of mutiple results.\n",
    "\n",
    "[Jump to section 3](#cap8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyser_full_chain.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to figure out why grey/red dots will be not displayed - I've added the results as images...\n",
    "for result in results:\n",
    "    orig_message = result[\"moderator\"][\"message\"]\n",
    "    print(f\"Original message: {orig_message}\")\n",
    "    df_evaluation, df_explanations = pretty_tables_single_result(result)\n",
    "    display(df_evaluation), display(df_explanations)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../visuals/tables_jupyter_github/message_0.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_1.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_2.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_3.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_4.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_5.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_6.png\">\n",
    "<img src=\"../visuals/tables_jupyter_github/message_7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings/Evaluation\n",
    "\n",
    "- The results are looking promising but there are issues we need to address:\n",
    "    - Original message: Adolf Hitler war ein deutscher Politiker... -> This is the first sentence about Adolf Hilter from wikipedia\n",
    "        - This Classifier correctly detects that the message is a historical reference\n",
    "        - But the Detector/Validator aren't able to classify the message properly because \"they\" rely on the keywords like antisemitic and racist which drives the chains to classify the message as \"direct hate speech\".\n",
    "        - The same is apply for the RW Rater\n",
    "    -   I have sometimes problems to replicate the results (It could be beneficial to pass the same message mutiple times into the chain and count the occurence? At least for the classifications and boolean outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deconstruct full analyser chain into components (18.02.24) <a id=\"cap8\"></a>\n",
    "[Back to Table of Content](#toc)\n",
    "\n",
    "> Please keep in mind that the model is not deterministic, the results can be slightly different if you're invoking it multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Hatespeech Detector Chain <a id=\"cap9\"></a>\n",
    "\n",
    "You can find all prompts in [this script](../src/ki_gegen_rechts/prompts.py).\n",
    "\n",
    "#### 3.1.1 The Prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"You are a hate speech expert. Your role is to categorize each message by analyzing its content for the presence and type of hate speech.\n",
    "Utilize the following definitions which are delimited with XML tags to ensure accurate and nuanced classifications:\n",
    "\n",
    "<category>Direct hate speech</category>\n",
    "<definition>This category is for messages where the author explicitly expresses hate speech. The content directly reflects the author's own views,\n",
    "showing an intention to disparage, demean, or express hostility towards individuals or groups based on race, ethnicity, religion, gender, sexual orientation,\n",
    "or other identity markers. Direct hate speech is characterized by the author's use of derogatory language, slurs, or any explicit statements that promote\n",
    "hatred or discrimination. if the message contains hate speech and is expressed by the author of the message and reflects directly his opinion.</definition>\n",
    "\n",
    "<category>Indirect hate speech</category>\n",
    "<definition>Assign a message to this category if it contains hate speech articulated through the lens of personal experiences\n",
    "or observations, yet does not directly express the author's personal hateful beliefs. This includes scenarios where the author discusses hate speech encountered\n",
    "in personal experiences, shares narratives that include hate speech to highlight societal issues, or articulates scenarios involving hate speech without endorsing it.\n",
    "This category also could include quoting someone else's hate speech</definition>\n",
    "\n",
    "<category>No hate speech</category>\n",
    "<definition>Messages without any form of hate speech, derogatory, discriminatory, or hostile language towards any group or individual,\n",
    "belong here. This includes content that is neutral, positive, or unrelated to hate speech.</definition>\n",
    "\n",
    "<category>Review needed</category>\n",
    "<definition>Messages without any form of hate speech, derogatory, discriminatory, or hostile language towards any group or individual,\n",
    "belong here. This includes content that is neutral, positive, or unrelated to hate speech.</definition>\n",
    "\n",
    "<category>Unknown</category>\n",
    "<definition>If the classification is unclear due to lack of context, ambiguous language, or other factors preventing a definitive categorization,\n",
    "label the message as \"Unknown.\" This category is for messages that need additional information or context for accurate classification.</definition>\n",
    "\n",
    "Carefully read each message, paying close attention to the context and the language used. Always think step by step and decide based on your conclusion.\n",
    "Your detailed assessment is vital for ensuring a respectful and safe communication environment.\n",
    "First explain your conclusion in 80 words and categorize it. Always answer in the following format:\n",
    "{format_instructions}\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "Answer:\"\"\"\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Invoking the Hatespeech Detector\n",
    "\n",
    "<b>Inputs: </b>\n",
    "- message\n",
    "\n",
    "<b>Outputs: JSON with following keys</b>\n",
    "- classification: Classify with a string if the message is 'Direct hate speech', 'Indirect hate speech', 'No hate speech', 'Review needed' or 'Unknown'\n",
    "- explanation: An explanation of the model's decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ki_gegen_rechts.prompts import HATESPEECH_DETECTOR_PROMPT, HatespeechDetectionFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"explanation\": \"The message contains explicit hate speech targeting Jews, using derogatory language and expressing a desire for their extermination. The author's intention is to disparage and promote hatred towards this group.\",\n",
      "    \"classification\": \"Direct hate speech\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=HatespeechDetectionFormat)\n",
    "chain = llm_chains.create_public_chat_gpt_chain(HATESPEECH_DETECTOR_PROMPT, parser)\n",
    "result = chain.invoke(message)\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Hatespeech Validator Chain <a id=\"cap10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ki_gegen_rechts.prompts import HATESPEECH_VALIDATOR_PROMPT, HatespeechValidatorFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 The Prompt\n",
    "\n",
    "```python\n",
    "\"\"\"You are tasked with re-evaluating the classification of a message that has been previously \n",
    "assessed by another expert in the context of hate speech detection. \n",
    "The message could fall into one of the following categories:\n",
    "\n",
    "    `Direct hate speech`: The message contains hate speech expressed directly by the author. This does not include any personal experience where the author was the victim of hate speech.\n",
    "    `Indirect hate speech`: The message contains hate speech that is not directly expressed by the author but implies endorsement or propagation of hate speech.\n",
    "    `No hate speech`: The message does not exhibit any characteristics of hate speech.\n",
    "    `Review needed`: The message exhibits some characteristics of hate speech but is not definitive, and therefore, further review is necessary.\n",
    "    `Unknown`: The message could not be confidently classified due to ambiguity or lack of clear indicators.\n",
    "    \n",
    "Instructions: Carefully read the message, paying close attention to the context and the language used. Accurately apply the categories based on\n",
    "the provided definitions, focusing on how hate speech is presented and the author's intent. Your detailed assessment is vital for ensuring a respectful\n",
    "and safe communication environment. Always think step by step and decide based on your conclusion. Provide your perspective to the message and explain your conclusion.\n",
    "\n",
    "Here is the classification provided by the previous expert below:\n",
    "<opinion>    \n",
    "Classification: {classification}\n",
    "</opinion>    \n",
    "\n",
    "Review the content of the message:\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "Always answer in the following format:\n",
    "{format_instructions}\n",
    "\n",
    "Answer:\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Invoke the Hatespeech Validator\n",
    "\n",
    "<b>Inputs: </b>\n",
    "- message\n",
    "- classification (of the Hatespeech Detector chain)\n",
    "\n",
    "<b>Outputs: JSON with following keys</b>\n",
    "- classification: Classify with a string if the message is 'Direct hate speech', 'Indirect hate speech', 'No hate speech', 'Review needed' or 'Unknown'\n",
    "- explanation: An explanation of the model's decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.update(message) # we need to pass the classification of the hatespeech detector and the original message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"classification\": \"Direct hate speech\",\n",
      "    \"explanation\": \"I agree with the previous expert's classification. The message contains direct hate speech targeting Jews, expressing a desire for them to be gassed. The reference to Hitler's work not being finished further emphasizes the hateful intent of the message.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=HatespeechValidatorFormat)\n",
    "chain_2 = llm_chains.create_public_chat_gpt_chain(HATESPEECH_VALIDATOR_PROMPT,\n",
    "                                                  parser)\n",
    "print(json.dumps(chain_2.invoke(result), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Hatespeech Classifier Chain <a id=\"cap11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ki_gegen_rechts.prompts import HATESPEECH_CLASSIFICATION_PROMPT, HatespeechClassifierFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 The Prompt\n",
    "\n",
    "```python\n",
    "\"\"\"Please analyze the following message and categorize its content based on the listed categories.\n",
    "Categorize the message in two major steps.\n",
    "\n",
    "In the first step you categorize if one of the following main categories apply to the message:\n",
    "\n",
    "    - Personal experience: Indicate if the message includes personal stories, anecdotes, or life experiences, where the author of the message suffered with hate speech.\n",
    "    - Historical reference: Identify references or quotes to historical events, figures, or contexts. Only classify it as an `historical reference` if the historical content is used to provide information and is not used to insult specific groups or persons.\n",
    "    - Offensive insult: The message clearly insults, discriminates or promoting hate and violence against particular groups, persons, and others.\n",
    "\n",
    "In the second step you identify if the message contains any elements of racism, antisemitism, homophobia, ableism, sexism or other forms of hate speech.\n",
    "\n",
    "Subcategories to analyze in the second step:\n",
    "\n",
    "    - Racism: Identify any elements that promote, condone, or express prejudice, discrimination, or antagonism against a person or people based on their race or ethnic origin.\n",
    "    - Antisemitism: Detect any expressions or actions that show hostility, prejudice, or discrimination against Jewish people.\n",
    "    - Homophobia: Highlight statements or attitudes that express dislike of or prejudice against homosexual people.\n",
    "    - Ableism: Point out any discrimination or social prejudice against people with disabilities or who are perceived to be disabled.\n",
    "    - Violence: Indicate if the message promotes violence in any form or threatens particular groups, persons, and others.\n",
    "    - Sexism: Highlight expressions or actions that show prejudice, discrimination, or antagonism based on gender, including demeaning statements, enforcement of traditional gender roles, or denial of opportunities due to gender.\n",
    "    - Other hate speech: Identify any content that doesn't fall into the above categories but can be considered as promoting hate or discrimination against a particular group based on attributes such as gender, sexual orientation, religion, or others.\n",
    "\n",
    "    \n",
    "General instructions:\n",
    "    - Analyze the content of the message carefully.\n",
    "    - Categorize the second step with python booleans format and don't save it as a string.\n",
    "    - If a subcategory does not apply, simply state false and move on to the next one.\n",
    "    - Maintain an objective and unbiased stance throughout the analysis.\n",
    "    - Always think step by step and decide based on your conclusion.\n",
    "\n",
    "Always answer in the following format:\n",
    "{format_instructions}\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Invoke the Hatespeech Classifier\n",
    "\n",
    "<b>Inputs: </b>\n",
    "- message\n",
    "\n",
    "<b>Outputs: JSON with following keys</b>\n",
    "- classification: Classify with a string if the message is a 'Personal experience', 'Historical reference' or 'Offensive Result'\n",
    "- Booleans to different hatespeech subcategories, see prompt (True if the message contains subcategory).\n",
    "- explanation: An explanation of the model's decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"classification\": \"Offensive insult\",\n",
      "    \"racism\": true,\n",
      "    \"anitsemitism\": true,\n",
      "    \"homophobia\": false,\n",
      "    \"ableism\": false,\n",
      "    \"violence\": true,\n",
      "    \"sexism\": false,\n",
      "    \"other_hate_speech\": false,\n",
      "    \"explanation\": \"The message contains offensive insults targeting Jewish people, promoting violence and expressing antisemitism.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=HatespeechClassifierFormat)\n",
    "chain_3 = llm_chains.create_public_chat_gpt_chain(HATESPEECH_CLASSIFICATION_PROMPT, parser)\n",
    "print(json.dumps(chain_3.invoke(result), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Right-Wing Rater <a id=\"cap12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ki_gegen_rechts.prompts import RightWingRatingFormat, RIGHT_WING_RATING_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 The Prompt\n",
    "\n",
    "```python\n",
    "\"\"\"You are an expert in understanding a broad spectrum of political ideologies, with a focus on recognizing extreme and harmful rhetoric, including fascism, Nazism, and racial supremacy. You possess a deep understanding of historical contexts, particularly related to Germany's history. Your task is to analyze messages in the first step if the message contain any indication of right-wing ideologies and then rate them into four categories, based on the presence and intensity of harmful right-wing ideologies. It is crucial to capture the intensity of the author's emotions, including feelings of strong dislike or aversion. If the message describes situations where the author was the victim of right-wing ideologies, this should be classified with no right-wing ideologies.\n",
    "\n",
    "First step - Right-wing Indication:\n",
    "    Classify with a boolean if the message contains any indication of right-wing ideologies. \n",
    "\n",
    "Second Step - Rating Scale:\n",
    "    Category 0: The message contains no indication of right-wing ideologies.\n",
    "    Category 1: The message contains subtle hints of right-wing ideologies but is not overtly harmful or inciting.\n",
    "    Category 2: The message contains clear right-wing ideological rhetoric, promoting a divisive or exclusionary viewpoint, potentially harmful which needs be reported and further reviewed.\n",
    "    Category 3: The message is extremely dangerous and constitutes a severe violation of German law. It openly advocates for violence, hatred, or supremacy based on right-wing extremist ideologies. Immediate action is required: reporting the content to the platform it was found on, and notifying law enforcement or other relevant authorities to assess the need for pressing charges.\n",
    "\n",
    "Always think step by step and decide based on your conclusion. Also explain why and which part in the message was the most relevant for your conclusion.\n",
    "\n",
    "Always answer in the following format:\n",
    "{format_instructions}\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Invoke the Right-wing Rater\n",
    "\n",
    "<b>Inputs: </b>\n",
    "- message\n",
    "\n",
    "<b>Outputs: JSON with following keys</b>\n",
    "- right_wing_indicator, which should indicate with a boolean if the message contains rw ideologies (True, if it applies)\n",
    "- rating from zero to 3. Category zero means, there is no rw ideologies. Category 3 is the max possible rating.\n",
    "- explanation: An explanation of the model's decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"right_wing_indicator\": true,\n",
      "    \"rating\": \"Category 3\",\n",
      "    \"explanation\": \"The message contains explicit and extreme right-wing rhetoric, advocating for the genocide of Jewish people. It openly promotes violence and hatred based on racial supremacy, which is a severe violation of German law. Immediate action is required to report the content to the platform it was found on, and notify law enforcement or other relevant authorities to assess the need for pressing charges.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=RightWingRatingFormat)\n",
    "chain_4 = llm_chains.create_public_chat_gpt_chain(RIGHT_WING_RATING_PROMPT, parser)\n",
    "print(json.dumps(chain_4.invoke(result), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Moderation Classifier from OpenAI (not a LLM Chain) <a id=\"cap13\"></a>\n",
    "[Back to Table of Content](#toc)\n",
    "\n",
    "For details on this chain, look up openai's guide for moderation [here](https://platform.openai.com/docs/guides/moderation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"message\": \"Diese gierigen Juden geh\\u00f6ren vergast - leider hat Hilter seine Arbeit damals nicht beendet.\",\n",
      "    \"mod_results\": {\n",
      "        \"categories\": {\n",
      "            \"harassment\": true,\n",
      "            \"harassment_threatening\": true,\n",
      "            \"hate\": true,\n",
      "            \"hate_threatening\": true,\n",
      "            \"self_harm\": false,\n",
      "            \"self_harm_instructions\": false,\n",
      "            \"self_harm_intent\": false,\n",
      "            \"sexual\": false,\n",
      "            \"sexual_minors\": false,\n",
      "            \"violence\": true,\n",
      "            \"violence_graphic\": false,\n",
      "            \"self-harm\": false,\n",
      "            \"sexual/minors\": false,\n",
      "            \"hate/threatening\": true,\n",
      "            \"violence/graphic\": false,\n",
      "            \"self-harm/intent\": false,\n",
      "            \"self-harm/instructions\": false,\n",
      "            \"harassment/threatening\": true\n",
      "        },\n",
      "        \"category_scores\": {\n",
      "            \"harassment\": 0.9950785636901855,\n",
      "            \"harassment_threatening\": 0.9740835428237915,\n",
      "            \"hate\": 0.9758500456809998,\n",
      "            \"hate_threatening\": 0.7414653301239014,\n",
      "            \"self_harm\": 8.119581252685748e-06,\n",
      "            \"self_harm_instructions\": 7.503008987441717e-07,\n",
      "            \"self_harm_intent\": 4.811929102288559e-06,\n",
      "            \"sexual\": 5.383280586102046e-05,\n",
      "            \"sexual_minors\": 6.507869443339587e-07,\n",
      "            \"violence\": 0.9802851676940918,\n",
      "            \"violence_graphic\": 0.00483097555115819,\n",
      "            \"self-harm\": 8.119581252685748e-06,\n",
      "            \"sexual/minors\": 6.507869443339587e-07,\n",
      "            \"hate/threatening\": 0.7414653301239014,\n",
      "            \"violence/graphic\": 0.00483097555115819,\n",
      "            \"self-harm/intent\": 4.811929102288559e-06,\n",
      "            \"self-harm/instructions\": 7.503008987441717e-07,\n",
      "            \"harassment/threatening\": 0.9740835428237915\n",
      "        },\n",
      "        \"flagged\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ki_gegen_rechts.llm_chains import OpenAIModerationChain\n",
    "mod_chain = OpenAIModerationChain()\n",
    "print(json.dumps(mod_chain.invoke(message, return_only_outputs=False), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conlusion and next steps <a id=\"cap14\"></a>\n",
    "\n",
    "The first attempt is going in the right direction but it's not really scalable or useable for a proper benchmark. There are definitely some points in the prompt where I can refine the prompt. The right wing rater is not really reliable and I assume that it's better to use this chain after the others with some kind of chain routing. The reviewer or hatespeech validator often uses the same words like the detector, so it's maybe better to change the prompt or use another LLM model/different parameters.\n",
    "\n",
    "\n",
    "The next steps will include:\n",
    "\n",
    "- Refine prompts and parallel chain logic \n",
    "- Save message and results in a database (prepare for potential fine-tuning)\n",
    "- Build an evaluation tool (accuracy, recall, precision or f1 for single label/multilabel) for the batched LLM output\n",
    "- Build an app/dashboard to show evaluation results\n",
    "- Use different LLM models (models which are trained for the german language)\n",
    "- Build Message collectors for social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
